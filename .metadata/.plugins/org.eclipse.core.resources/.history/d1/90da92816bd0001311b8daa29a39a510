
import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.RunningJob;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class CallJobFromServlet extends HttpServlet {

    protected void doGet(HttpServletRequest request,HttpServletResponse response) throws ServletException, IOException {

    	String regex = "^[>].*";
		 
		Configuration conf = new Configuration();
		conf.set("record.delimiter.regex", regex);
		//conf.set("textinputformat.record.delimiter", "");
		//conf.set("mapreduce.output.textoutputformat.separator", ";");
		    
		Job job = new Job(conf, "wordcount");
		job.setJarByClass(CallJobFromServlet.class);
		
		Path output1 = new Path("hdfs://master:54310/user/hduser/Genome/dp-out");
		output1.getFileSystem(conf).delete(output1, true);
		
		job.setOutputKeyClass(LongWritable.class);
		job.setOutputValueClass(Text.class);
		    
		job.setMapperClass(Map.class);
		job.setReducerClass(Reduce.class);
		    
		job.setInputFormatClass(PatternInputFormat.class);
		//job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(CustomOutputFormat.class);
		    
		FileInputFormat.addInputPath(job, new Path("hdfs://master:54310/user/hduser/Genome/seq6.fa"));
		FileOutputFormat.setOutputPath(job, new Path("hdfs://master:54310/user/hduser/Genome/dp-out"));
		
		RunningJob jerb = JobClient.runJob(conf);
		
		try{
			job.waitForCompletion(true);
		}catch(Exception e){}
		//System.out.println(total);
		
		while(!job.isComplete()){
			try{
			Thread.sleep(5000);
			}catch(Exception e){}
		}
   }
}